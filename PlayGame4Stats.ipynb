{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KMewUp8TJtBP",
    "outputId": "d43de1a3-bea5-4bcf-91d8-65b301000f9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\OneDrive\\Desktop\\Codenames Progetto PDE\\Codenames-LLM\\codenames_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import codenamesLLM\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from tqdm import tqdm\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAY AGGREGATE MIXED GUESSERS GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing gpt-4o vs mixed (1/48)\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"experiment_data\\mixed_guessers_data\\mixed_guessers_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "total_games = len(df)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    red_guesser_team = [row['rg1'], row['rg2'], row['rg3']]\n",
    "    red_guesser_label = \"mixed\" if (red_guesser_team[0] != red_guesser_team[1]) else red_guesser_team[0]\n",
    "    blue_guesser_team = [row['bg1'], row['bg2'], row['bg3']]\n",
    "    blue_guesser_label = \"mixed\" if (blue_guesser_team[0] != blue_guesser_team[1]) else blue_guesser_team[0]\n",
    "\n",
    "    playable = True\n",
    "    already_played = pd.notna(row['winner'])\n",
    "\n",
    "    if not(already_played) and playable:\n",
    "        try:\n",
    "            print(f\"playing {red_guesser_label} vs {blue_guesser_label} ({index}/{total_games})\")\n",
    "            result = codenamesLLM.play_game_mixed_guessers(red_master_model=\"grok-beta\",\n",
    "                                                        red_guesser_model=red_guesser_team,\n",
    "                                                        blue_master_model=\"grok-beta\",\n",
    "                                                        blue_guesser_model=blue_guesser_team)\n",
    "            \n",
    "            print(result)\n",
    "            red_stats = codenamesLLM.analyze_team_guesses(result[3], \"RED\")\n",
    "            blue_stats = codenamesLLM.analyze_team_guesses(result[3], \"BLUE\")\n",
    "\n",
    "            df.at[index, 'red_model'] = red_guesser_label\n",
    "            df.at[index, 'blue_model'] = blue_guesser_label\n",
    "            df.at[index, 'winner'] = result[0]\n",
    "            df.at[index, 'red_avg_words_2guess'] = red_stats['average_expected_guesses']\n",
    "            df.at[index, 'blue_avg_words_2guess'] = blue_stats['average_expected_guesses']\n",
    "            df.at[index, 'red_avg_words_guessed'] = red_stats['average_correct_guesses']\n",
    "            df.at[index, 'blue_avg_words_guessed'] = blue_stats['average_correct_guesses']\n",
    "            df.at[index, 'reason'] = result[1]\n",
    "            df.at[index, 'red_turns'] = red_stats['total_hints']\n",
    "            df.at[index, 'blue_turns'] = blue_stats['total_hints']\n",
    "            df.at[index, 'red_cib'] = result[4]\n",
    "            df.at[index, 'blue_cib'] = result[5]\n",
    "\n",
    "            df.to_excel(file_path, index=False)\n",
    "            print(\"game saved.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"skipped game: {e}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAY AGGREGATE GAMES BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Excel file\n",
    "file_path = r\"experiment_data\\best_model\\best_model.xlsx\" #compy the model_tournament_input to use one new\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Iterate through the rows using titled columns\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Access values using column titles\n",
    "    red_team = row['red_model']  # Replace with the actual column title for the red team\n",
    "    blue_team = row['blue_model']  # Replace with the actual column title for the blue team\n",
    "\n",
    "    if red_team == \"grok-claude\":\n",
    "        red_master_model = \"grok-beta\"\n",
    "        red_guesser_model = \"claude-3-5-sonnet-latest\"\n",
    "    else:\n",
    "        red_master_model = red_team\n",
    "        red_guesser_model = red_team\n",
    "\n",
    "    if blue_team == \"grok-claude\":\n",
    "        blue_master_model = \"grok-beta\"\n",
    "        blue_guesser_model = \"claude-3-5-sonnet-latest\"\n",
    "    else:\n",
    "        blue_master_model = blue_team\n",
    "        blue_guesser_model = blue_team\n",
    "\n",
    "    playable = True\n",
    "    already_played = pd.notna(row['winner'])\n",
    "\n",
    "    if ((pd.notna(red_team) and pd.notna(blue_team)) and not(already_played)) and playable:  # Check if both values are not NaN\n",
    "        try:\n",
    "            # Call your function and get the result\n",
    "            print(f\"playing {red_team} vs {blue_team}...\")\n",
    "            result = codenamesLLM.play_game(red_master_model=red_master_model,\n",
    "                                            red_guesser_model=red_guesser_model,\n",
    "                                            blue_master_model=blue_master_model,\n",
    "                                            blue_guesser_model=blue_guesser_model)\n",
    "            \n",
    "            print(result)\n",
    "            red_stats = codenamesLLM.analyze_team_guesses(result[3], \"RED\")\n",
    "            blue_stats = codenamesLLM.analyze_team_guesses(result[3], \"BLUE\")\n",
    "\n",
    "            df.at[index, 'red_model'] = red_team\n",
    "            df.at[index, 'blue_model'] = blue_team\n",
    "            df.at[index, 'winner'] = result[0]\n",
    "            df.at[index, 'red_avg_words_2guess'] = red_stats['average_expected_guesses']\n",
    "            df.at[index, 'blue_avg_words_2guess'] = blue_stats['average_expected_guesses']\n",
    "            df.at[index, 'red_avg_words_guessed'] = red_stats['average_correct_guesses']\n",
    "            df.at[index, 'blue_avg_words_guessed'] = blue_stats['average_correct_guesses']\n",
    "            df.at[index, 'reason'] = result[1]\n",
    "            df.at[index, 'red_turns'] = red_stats['total_hints']\n",
    "            df.at[index, 'blue_turns'] = blue_stats['total_hints']\n",
    "            df.at[index, 'red_cib'] = result[4]\n",
    "            df.at[index, 'blue_cib'] = result[5]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"skipped game: {e}\")\n",
    "\n",
    "    # Write the updated DataFrame back to the same Excel file\n",
    "    df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI8lD9o5JtBW"
   },
   "source": [
    "# TOURNAMENT DATA PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sRYFIAZTJtBW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_tournament_data(input_path, output_path):\n",
    "    # Load the data\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # Function to calculate metrics\n",
    "    def calculate_metrics(group):\n",
    "        wins = group['winner'] == group['role'].str.upper()\n",
    "        losses = ~wins\n",
    "        card_finished = group['reason'] == 'cards finished'\n",
    "        killer_word = group['reason'] == 'killer word selected'\n",
    "\n",
    "        return {\n",
    "            \"model_name\": group[\"model\"].iloc[0],\n",
    "            \"games_played\": len(group),\n",
    "            \"wins\": wins.sum(),\n",
    "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
    "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
    "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
    "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
    "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
    "            \"average_word_to_guess\": group['avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins\": group.loc[wins, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_lose\": group.loc[losses, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_guessed\": group['avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins\": group.loc[wins, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_lose\": group.loc[losses, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_guessed'].mean(),\n",
    "            \"average_turns\": group['turns'].mean(),\n",
    "            \"average_turns_when_wins\": group.loc[wins, 'turns'].mean(),\n",
    "            \"average_turns_when_lose\": group.loc[losses, 'turns'].mean(),\n",
    "            \"average_turns_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'turns'].mean(),\n",
    "            \"average_turns_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'turns'].mean(),\n",
    "            \"average_turns_when_wins_by_killer_cards\": group.loc[wins & killer_word, 'turns'].mean(),\n",
    "            \"average_turns_when_loses_by_killer_cards\": group.loc[losses & killer_word, 'turns'].mean(),\n",
    "            \"total_cib\": group['cib'].sum()\n",
    "        }\n",
    "\n",
    "    # Reshape the dataset to treat roles equivalently\n",
    "    red_df = df.rename(columns=lambda x: x.replace('red_', '')).assign(role='red', model=df['red_model'])\n",
    "    blue_df = df.rename(columns=lambda x: x.replace('blue_', '')).assign(role='blue', model=df['blue_model'])\n",
    "    combined_df = pd.concat([red_df, blue_df], ignore_index=True)\n",
    "\n",
    "    # Metrics for models as a whole\n",
    "    overall_metrics = combined_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "\n",
    "    # Metrics for models playing as Red\n",
    "    red_metrics = red_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "    red_metrics['role'] = 'red'\n",
    "\n",
    "    # Metrics for models playing as Blue\n",
    "    blue_metrics = blue_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "    blue_metrics['role'] = 'blue'\n",
    "\n",
    "    # Save the results to an Excel file with three sheets\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
    "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
    "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"vsclaude\", \"vsgpt\", \"vsgrok\"]:\n",
    "    input_path = r\"C:\\Users\\miche\\OneDrive\\Desktop\\codenames data backup\\bestmodel\\{}.xlsx\".format(model)\n",
    "    output_path = r\"C:\\Users\\miche\\OneDrive\\Desktop\\codenames data backup\\bestmodel\\{}_stats.xlsx\".format(model)\n",
    "\n",
    "    process_tournament_data(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3QkoRtpJtBX"
   },
   "source": [
    "# COT DATA PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:42: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:42: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2364130030.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  file_path = 'experiment_data\\cot_data\\cot_data_input.xlsx'\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2364130030.py:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df.to_excel('experiment_data\\cot_data\\cot_data_fra.xlsx', index=False)\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2364130030.py:42: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  print(f\"Results saved to experiment_data\\cot_data\\cot_data_fra.xlsx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing game 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2364130030.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'BLUE' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'winner'] = result[0]\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2364130030.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'killer word selected' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'reason'] = result[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing game 2\n",
      "playing game 3\n",
      "playing game 4\n",
      "playing game 5\n",
      "playing game 6\n",
      "playing game 7\n",
      "playing game 8\n",
      "playing game 9\n",
      "playing game 10\n",
      "playing game 11\n",
      "playing game 12\n",
      "playing game 13\n",
      "playing game 14\n",
      "playing game 15\n",
      "playing game 16\n",
      "playing game 17\n",
      "playing game 18\n",
      "playing game 19\n",
      "playing game 20\n",
      "playing game 21\n",
      "playing game 22\n",
      "playing game 23\n",
      "playing game 24\n",
      "playing game 25\n",
      "playing game 26\n",
      "playing game 27\n",
      "playing game 28\n",
      "playing game 29\n",
      "playing game 30\n",
      "playing game 31\n",
      "playing game 32\n",
      "playing game 33\n",
      "playing game 34\n",
      "playing game 35\n",
      "playing game 36\n",
      "playing game 37\n",
      "playing game 38\n",
      "playing game 39\n",
      "playing game 40\n",
      "playing game 41\n",
      "playing game 42\n",
      "playing game 43\n",
      "playing game 44\n",
      "playing game 45\n",
      "playing game 46\n",
      "playing game 47\n",
      "playing game 48\n",
      "playing game 49\n",
      "playing game 50\n",
      "playing game 51\n",
      "playing game 52\n",
      "playing game 53\n",
      "playing game 54\n",
      "playing game 55\n",
      "playing game 56\n",
      "playing game 57\n",
      "playing game 58\n",
      "playing game 59\n",
      "playing game 60\n",
      "playing game 61\n",
      "playing game 62\n",
      "playing game 63\n",
      "playing game 64\n",
      "playing game 65\n",
      "playing game 66\n",
      "playing game 67\n",
      "playing game 68\n",
      "playing game 69\n",
      "playing game 70\n",
      "playing game 71\n",
      "playing game 72\n",
      "playing game 73\n",
      "playing game 74\n",
      "playing game 75\n",
      "playing game 76\n",
      "playing game 77\n",
      "playing game 78\n",
      "playing game 79\n",
      "playing game 80\n",
      "playing game 81\n",
      "playing game 82\n",
      "playing game 83\n",
      "playing game 84\n",
      "playing game 85\n",
      "playing game 86\n",
      "playing game 87\n",
      "playing game 88\n",
      "playing game 89\n",
      "playing game 90\n",
      "playing game 91\n",
      "playing game 92\n",
      "playing game 93\n",
      "playing game 94\n",
      "playing game 95\n",
      "playing game 96\n",
      "playing game 97\n",
      "playing game 98\n",
      "playing game 99\n",
      "playing game 100\n",
      "Results saved to experiment_data\\cot_data\\cot_data_fra.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the uploaded file\n",
    "file_path = 'experiment_data\\cot_data\\cot_data_input.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "i = 0\n",
    "# Loop through each configuration in the data file\n",
    "for index, row in df.iterrows():\n",
    "    i += 1\n",
    "    red_cot = row['red_cot']\n",
    "    blue_cot = row['blue_cot']\n",
    "    playable = True\n",
    "    already_played = pd.notna(row['winner'])\n",
    "    # Call the play_game function with parameters from the row\n",
    "\n",
    "    if not already_played and playable:  # Check if both values are not NaN\n",
    "        try:\n",
    "\n",
    "            print(f\"playing game {i}\")\n",
    "            result = codenamesLLM.play_game(lang=\"eng\", n_cards=25, coloured_cards=7, k_cards=1, verbose=False, \n",
    "              red_master_model=\"gpt-4o-mini\", red_guesser_model=False, \n",
    "              red_cot=red_cot, red_cot_guesser=False, \n",
    "              blue_master_model=\"gpt-4o-mini\", blue_guesser_model=False, \n",
    "              blue_cot=blue_cot, blue_cot_guesser=False, \n",
    "              red_agents=3, blue_agents=3, masterverbose=False)\n",
    "\n",
    "            red_stats = codenamesLLM.analyze_team_guesses(result[3], \"RED\")\n",
    "            blue_stats = codenamesLLM.analyze_team_guesses(result[3], \"BLUE\")\n",
    "\n",
    "            df.at[index, 'winner'] = result[0]\n",
    "            df.at[index, 'red_avg_words_2guess'] = red_stats['average_expected_guesses']\n",
    "            df.at[index, 'blue_avg_words_2guess'] = blue_stats['average_expected_guesses']\n",
    "            df.at[index, 'red_avg_words_guessed'] = red_stats['average_correct_guesses']\n",
    "            df.at[index, 'blue_avg_words_guessed'] = blue_stats['average_correct_guesses']\n",
    "            df.at[index, 'reason'] = result[1]\n",
    "            df.at[index, 'red_turns'] = red_stats['total_hints']\n",
    "            df.at[index, 'blue_turns'] = blue_stats['total_hints']\n",
    "            df.at[index, 'red_cib'] = result[4]\n",
    "            df.at[index, 'blue_cib'] = result[5]    \n",
    "        except Exception as e:\n",
    "            print(f\"skipped game: {e}\")\n",
    "    df.to_excel('experiment_data\\cot_data\\cot_data_fra.xlsx', index=False)\n",
    "\n",
    "print(f\"Results saved to experiment_data\\cot_data\\cot_data_fra.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-N0VBPd9JtBX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_tournament_data_by_cot(input_path, output_path):\n",
    "    # Load the data\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # Function to calculate metrics\n",
    "    def calculate_metrics(group):\n",
    "        wins = group['winner'] == group['role'].str.upper()\n",
    "        losses = ~wins\n",
    "        card_finished = group['reason'] == 'cards finished'\n",
    "        killer_word = group['reason'] == 'killer word selected'\n",
    "\n",
    "        return {\n",
    "            \"cot\": group[\"cot\"].iloc[0],\n",
    "            \"games_played\": len(group),\n",
    "            \"wins\": wins.sum(),\n",
    "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
    "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
    "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
    "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
    "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
    "            \"average_word_to_guess\": group['avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins\": group.loc[wins, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_lose\": group.loc[losses, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_guessed\": group['avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins\": group.loc[wins, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_lose\": group.loc[losses, 'avg_words_guessed'].mean(),\n",
    "            \"average_turns\": group['turns'].mean(),\n",
    "            \"average_turns_when_wins\": group.loc[wins, 'turns'].mean(),\n",
    "            \"average_turns_when_lose\": group.loc[losses, 'turns'].mean(),\n",
    "            \"total_cib\": group['cib'].sum()\n",
    "        }\n",
    "\n",
    "    # Reshape the dataset to unify red and blue roles\n",
    "    red_df = df.rename(columns=lambda x: x.replace('red_', '')).assign(role='red', cot=df['red_cot'])\n",
    "    blue_df = df.rename(columns=lambda x: x.replace('blue_', '')).assign(role='blue', cot=df['blue_cot'])\n",
    "    combined_df = pd.concat([red_df, blue_df], ignore_index=True)\n",
    "\n",
    "    # Metrics for cot\n",
    "    overall_metrics = combined_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
    "\n",
    "    # Metrics for cot in Red role\n",
    "    red_metrics = red_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
    "    red_metrics['role'] = 'red'\n",
    "\n",
    "    # Metrics for cot in Blue role\n",
    "    blue_metrics = blue_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
    "    blue_metrics['role'] = 'blue'\n",
    "\n",
    "    # Save the results to an Excel file with three sheets\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
    "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
    "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_jneNS1BJtBY",
    "outputId": "894bfe7a-d6b2-40d9-ccd1-c41ecdff3de4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2191011510.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  input_path = 'experiment_data\\cot_data\\cot_data_input.xlsx'\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2191011510.py:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  output_path = 'experiment_data\\cot_data\\cot_data_fra.xlsx'\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2111975892.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  overall_metrics = combined_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2111975892.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  red_metrics = red_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
      "C:\\Users\\frmar\\AppData\\Local\\Temp\\ipykernel_13144\\2111975892.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  blue_metrics = blue_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_path = 'experiment_data\\cot_data\\cot_data_input.xlsx'\n",
    "output_path = 'experiment_data\\cot_data\\cot_data_fra.xlsx'\n",
    "process_tournament_data_by_cot(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeBKraGDJtBY"
   },
   "source": [
    "# AGENTS NUMBER DATA PROCESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsXtYOi2JvZZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_agents_data(input_path, output_path):\n",
    "    # Load the data\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # Function to calculate metrics\n",
    "    def calculate_metrics(group, role):\n",
    "        prefix = 'red_' if role == 'red' else 'blue_'\n",
    "        wins = (group['winner'] == role.upper())\n",
    "        losses = ~wins\n",
    "        card_finished = group['reason'] == 'cards finished'\n",
    "        killer_word = group['reason'] == 'killer word selected'\n",
    "\n",
    "        return {\n",
    "            \"number_of_agents\": group[f\"number_{role}_agents\"].iloc[0],\n",
    "            \"games_played\": len(group),\n",
    "            \"wins\": wins.sum(),\n",
    "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
    "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
    "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
    "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
    "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
    "            \"average_word_to_guess\": group[f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins\": group.loc[wins, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_lose\": group.loc[losses, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_killer_card\": group.loc[wins & killer_word, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_killer_card\": group.loc[losses & killer_word, f'{prefix}avg_words_2guess'].mean(),\n",
    "            \"average_word_guessed\": group[f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins\": group.loc[wins, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_lose\": group.loc[losses, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_killer_card\": group.loc[wins & killer_word, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_killer_card\": group.loc[losses & killer_word, f'{prefix}avg_words_guessed'].mean(),\n",
    "            \"average_turns\": group[f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_wins\": group.loc[wins, f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_lose\": group.loc[losses, f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_wins_by_killer_cards\": group.loc[wins & killer_word, f'{prefix}turns'].mean(),\n",
    "            \"average_turns_when_loses_by_killer_cards\": group.loc[losses & killer_word, f'{prefix}turns'].mean(),\n",
    "            \"total_cib\": group[f'{prefix}cib'].sum()\n",
    "        }\n",
    "\n",
    "    # Metrics for agents playing as Red\n",
    "    red_metrics = df.groupby(\"number_red_agents\").apply(lambda g: calculate_metrics(g, \"red\")).apply(pd.Series)\n",
    "    red_metrics['role'] = 'red'\n",
    "\n",
    "    # Metrics for agents playing as Blue\n",
    "    blue_metrics = df.groupby(\"number_blue_agents\").apply(lambda g: calculate_metrics(g, \"blue\")).apply(pd.Series)\n",
    "    blue_metrics['role'] = 'blue'\n",
    "\n",
    "    # Combine and calculate overall metrics\n",
    "    overall_metrics = (\n",
    "        pd.concat([red_metrics, blue_metrics])\n",
    "        .groupby(\"number_of_agents\")\n",
    "        .agg({\n",
    "            \"games_played\": \"sum\",\n",
    "            \"wins\": \"sum\",\n",
    "            \"win_percentage\": \"mean\",\n",
    "            \"win_by_cards_finished\": \"sum\",\n",
    "            \"wins_by_killer_words\": \"sum\",\n",
    "            \"losses_by_card_finished\": \"sum\",\n",
    "            \"losses_by_killer_words\": \"sum\",\n",
    "            \"average_word_to_guess\": \"mean\",\n",
    "            \"average_word_to_guess_when_wins\": \"mean\",\n",
    "            \"average_word_to_guess_when_lose\": \"mean\",\n",
    "            \"average_word_to_guess_when_wins_by_ending_cards\": \"mean\",\n",
    "            \"average_word_to_guess_when_loses_by_ending_cards\": \"mean\",\n",
    "            \"average_word_to_guess_when_wins_by_killer_card\": \"mean\",\n",
    "            \"average_word_to_guess_when_loses_by_killer_card\": \"mean\",\n",
    "            \"average_word_guessed\": \"mean\",\n",
    "            \"average_word_guessed_when_wins\": \"mean\",\n",
    "            \"average_word_guessed_when_lose\": \"mean\",\n",
    "            \"average_word_guessed_when_wins_by_ending_cards\": \"mean\",\n",
    "            \"average_word_guessed_when_loses_by_ending_cards\": \"mean\",\n",
    "            \"average_word_guessed_when_wins_by_killer_card\": \"mean\",\n",
    "            \"average_word_guessed_when_loses_by_killer_card\": \"mean\",\n",
    "            \"average_turns\": \"mean\",\n",
    "            \"average_turns_when_wins\": \"mean\",\n",
    "            \"average_turns_when_lose\": \"mean\",\n",
    "            \"average_turns_when_wins_by_ending_cards\": \"mean\",\n",
    "            \"average_turns_when_loses_by_ending_cards\": \"mean\",\n",
    "            \"average_turns_when_wins_by_killer_cards\": \"mean\",\n",
    "            \"average_turns_when_loses_by_killer_cards\": \"mean\",\n",
    "            \"total_cib\": \"sum\"\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Save the results to an Excel file with three sheets\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
    "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
    "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9Ioe0gMuJ9L1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_22320\\2518959492.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  red_metrics = df.groupby(\"number_red_agents\").apply(lambda g: calculate_metrics(g, \"red\")).apply(pd.Series)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_22320\\2518959492.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  blue_metrics = df.groupby(\"number_blue_agents\").apply(lambda g: calculate_metrics(g, \"blue\")).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "# Define input and output file paths\n",
    "input_path = r'experiment_data\\n_agents_data\\agents_data.xlsx'  # Replace with your input file path\n",
    "output_path = r'experiment_data\\n_agents_data\\agents_data_stats.xlsx'  # Replace with your output file path\n",
    "\n",
    "# Run the process\n",
    "process_agents_data(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "codenames_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
