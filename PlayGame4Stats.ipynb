{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMewUp8TJtBP",
        "outputId": "d43de1a3-bea5-4bcf-91d8-65b301000f9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\miche\\OneDrive\\Desktop\\Codenames Progetto PDE\\Codenames-LLM\\codenames_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import codenamesLLM\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqioRtqTJtBS"
      },
      "source": [
        "# PLAY AGGREGATE GAMES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGv77exZJtBV",
        "outputId": "85996fbf-a643-47eb-95e2-c08b2716f09a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 30/120 [01:12<08:44,  5.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 5(False cot) ->  killer word selected\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 42/120 [01:24<02:35,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 3(False cot)  ->  killer word selected\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 50/120 [04:44<17:55, 15.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 3(False cot) ->  cards finished\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 98/120 [08:47<06:27, 17.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 4(False cot)  ->  cards finished\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 100/120 [13:53<16:13, 48.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 5(False cot)  ->  cards finished\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 106/120 [17:33<09:00, 38.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner: 2(False cot) ->  killer word selected\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 120/120 [17:33<00:00,  8.78s/it]\n"
          ]
        }
      ],
      "source": [
        "# Path to your Excel file\n",
        "file_path = r\"experiment_data\\n_agents_data\\agents_data.xlsx\" #compy the model_tournament_input to use one new\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Iterate through the rows using titled columns\n",
        "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    # Access values using column titles\n",
        "    red_team = row['red_agents']  # Replace with the actual column title for the red team\n",
        "    blue_team = row['blue_agents']  # Replace with the actual column title for the blue team\n",
        "    red_cot = row['red_cot']\n",
        "    blue_cot = row['blue_cot']\n",
        "    playable = True\n",
        "    already_played = pd.notna(row['winner'])\n",
        "\n",
        "    if ((pd.notna(red_team) and pd.notna(blue_team)) and not(already_played)) and playable:  # Check if both values are not NaN\n",
        "        try:\n",
        "            # Call your function and get the result\n",
        "            result = codenamesLLM.play_game(red_agents=red_team, red_cot_guesser=red_cot, blue_agents=blue_team, blue_cot_guesser=blue_cot)\n",
        "            print(\"winner:\",f\"{red_team}({red_cot} cot)\" if result[0] == \"RED\" else f\"{blue_team}({blue_cot} cot) \",\"-> \", result[1])\n",
        "            red_stats = codenamesLLM.analyze_team_guesses(result[3], \"RED\")\n",
        "            blue_stats = codenamesLLM.analyze_team_guesses(result[3], \"BLUE\")\n",
        "\n",
        "            df.at[index, 'red_agents'] = red_team\n",
        "            df.at[index, 'red_cot'] = red_cot\n",
        "            df.at[index, 'blue_agents'] = blue_team\n",
        "            df.at[index, 'blue_cot'] = blue_cot\n",
        "            df.at[index, 'winner'] = result[0]\n",
        "            df.at[index, 'red_avg_words_2guess'] = red_stats['average_expected_guesses']\n",
        "            df.at[index, 'blue_avg_words_2guess'] = blue_stats['average_expected_guesses']\n",
        "            df.at[index, 'red_avg_words_guessed'] = red_stats['average_correct_guesses']\n",
        "            df.at[index, 'blue_avg_words_guessed'] = blue_stats['average_correct_guesses']\n",
        "            df.at[index, 'reason'] = result[1]\n",
        "            df.at[index, 'red_turns'] = red_stats['total_hints']\n",
        "            df.at[index, 'blue_turns'] = blue_stats['total_hints']\n",
        "            df.at[index, 'red_cib'] = result[4]\n",
        "            df.at[index, 'blue_cib'] = result[5]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"skipped game: {e}\")\n",
        "\n",
        "    # Write the updated DataFrame back to the same Excel file\n",
        "    df.to_excel(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8lD9o5JtBW"
      },
      "source": [
        "# TOURNAMENT DATA PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRYFIAZTJtBW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_tournament_data(input_path, output_path):\n",
        "    # Load the data\n",
        "    df = pd.read_excel(input_path)\n",
        "\n",
        "    # Function to calculate metrics\n",
        "    def calculate_metrics(group):\n",
        "        wins = group['winner'] == group['role'].str.upper()\n",
        "        losses = ~wins\n",
        "        card_finished = group['reason'] == 'cards finished'\n",
        "        killer_word = group['reason'] == 'killer word selected'\n",
        "\n",
        "        return {\n",
        "            \"model_name\": group[\"model\"].iloc[0],\n",
        "            \"games_played\": len(group),\n",
        "            \"wins\": wins.sum(),\n",
        "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
        "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
        "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
        "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
        "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
        "            \"average_word_to_guess\": group['avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins\": group.loc[wins, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_lose\": group.loc[losses, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_guessed\": group['avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins\": group.loc[wins, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_lose\": group.loc[losses, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_guessed'].mean(),\n",
        "            \"average_turns\": group['turns'].mean(),\n",
        "            \"average_turns_when_wins\": group.loc[wins, 'turns'].mean(),\n",
        "            \"average_turns_when_lose\": group.loc[losses, 'turns'].mean(),\n",
        "            \"average_turns_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'turns'].mean(),\n",
        "            \"average_turns_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'turns'].mean(),\n",
        "            \"average_turns_when_wins_by_killer_cards\": group.loc[wins & killer_word, 'turns'].mean(),\n",
        "            \"average_turns_when_loses_by_killer_cards\": group.loc[losses & killer_word, 'turns'].mean(),\n",
        "            \"total_cib\": group['cib'].sum()\n",
        "        }\n",
        "\n",
        "    # Reshape the dataset to treat roles equivalently\n",
        "    red_df = df.rename(columns=lambda x: x.replace('red_', '')).assign(role='red', model=df['red_model'])\n",
        "    blue_df = df.rename(columns=lambda x: x.replace('blue_', '')).assign(role='blue', model=df['blue_model'])\n",
        "    combined_df = pd.concat([red_df, blue_df], ignore_index=True)\n",
        "\n",
        "    # Metrics for models as a whole\n",
        "    overall_metrics = combined_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
        "\n",
        "    # Metrics for models playing as Red\n",
        "    red_metrics = red_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
        "    red_metrics['role'] = 'red'\n",
        "\n",
        "    # Metrics for models playing as Blue\n",
        "    blue_metrics = blue_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
        "    blue_metrics['role'] = 'blue'\n",
        "\n",
        "    # Save the results to an Excel file with three sheets\n",
        "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
        "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
        "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
        "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUzHStthJtBX"
      },
      "outputs": [],
      "source": [
        "input_path = 'experiment_data\\model_tournament\\model_tournament.xlsx'  # Replace with your input file path\n",
        "output_path = 'experiment_data\\model_tournament\\model_tournament_stats.xlsx'  # Replace with your output file path\n",
        "\n",
        "# Run the process\n",
        "process_tournament_data(input_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3QkoRtpJtBX"
      },
      "source": [
        "# COT DATA PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N0VBPd9JtBX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_tournament_data_by_cot(input_path, output_path):\n",
        "    # Load the data\n",
        "    df = pd.read_excel(input_path)\n",
        "\n",
        "    # Function to calculate metrics\n",
        "    def calculate_metrics(group):\n",
        "        wins = group['winner'] == group['role'].str.upper()\n",
        "        losses = ~wins\n",
        "        card_finished = group['reason'] == 'cards finished'\n",
        "        killer_word = group['reason'] == 'killer word selected'\n",
        "\n",
        "        return {\n",
        "            \"cot\": group[\"cot\"].iloc[0],\n",
        "            \"games_played\": len(group),\n",
        "            \"wins\": wins.sum(),\n",
        "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
        "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
        "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
        "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
        "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
        "            \"average_word_to_guess\": group['avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins\": group.loc[wins, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_lose\": group.loc[losses, 'avg_words_2guess'].mean(),\n",
        "            \"average_word_guessed\": group['avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins\": group.loc[wins, 'avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_lose\": group.loc[losses, 'avg_words_guessed'].mean(),\n",
        "            \"average_turns\": group['turns'].mean(),\n",
        "            \"average_turns_when_wins\": group.loc[wins, 'turns'].mean(),\n",
        "            \"average_turns_when_lose\": group.loc[losses, 'turns'].mean(),\n",
        "            \"total_cib\": group['cib'].sum()\n",
        "        }\n",
        "\n",
        "    # Reshape the dataset to unify red and blue roles\n",
        "    red_df = df.rename(columns=lambda x: x.replace('red_', '')).assign(role='red', cot=df['red_cot'])\n",
        "    blue_df = df.rename(columns=lambda x: x.replace('blue_', '')).assign(role='blue', cot=df['blue_cot'])\n",
        "    combined_df = pd.concat([red_df, blue_df], ignore_index=True)\n",
        "\n",
        "    # Metrics for cot\n",
        "    overall_metrics = combined_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
        "\n",
        "    # Metrics for cot in Red role\n",
        "    red_metrics = red_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
        "    red_metrics['role'] = 'red'\n",
        "\n",
        "    # Metrics for cot in Blue role\n",
        "    blue_metrics = blue_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
        "    blue_metrics['role'] = 'blue'\n",
        "\n",
        "    # Save the results to an Excel file with three sheets\n",
        "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
        "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
        "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
        "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jneNS1BJtBY",
        "outputId": "894bfe7a-d6b2-40d9-ccd1-c41ecdff3de4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_28900\\2111975892.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  overall_metrics = combined_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
            "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_28900\\2111975892.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  red_metrics = red_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n",
            "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_28900\\2111975892.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  blue_metrics = blue_df.groupby(\"cot\").apply(calculate_metrics).apply(pd.Series)\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "input_path = 'experiment_data\\cot_data\\cot_data.xlsx'\n",
        "output_path = 'experiment_data\\cot_data\\cot_data_stats.xlsx'\n",
        "process_tournament_data_by_cot(input_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeBKraGDJtBY"
      },
      "source": [
        "# AGENTS NUMBER DATA PROCESS\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_agents_data(input_path, output_path):\n",
        "    # Load the data\n",
        "    df = pd.read_excel(input_path)\n",
        "\n",
        "    # Function to calculate metrics\n",
        "    def calculate_metrics(group, role):\n",
        "        prefix = 'red_' if role == 'red' else 'blue_'\n",
        "        wins = (group['winner'] == role.upper())\n",
        "        losses = ~wins\n",
        "        card_finished = group['reason'] == 'cards finished'\n",
        "        killer_word = group['reason'] == 'killer word selected'\n",
        "\n",
        "        return {\n",
        "            \"number_of_agents\": group[f\"number_{role}_agents\"].iloc[0],\n",
        "            \"games_played\": len(group),\n",
        "            \"wins\": wins.sum(),\n",
        "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
        "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
        "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
        "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
        "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
        "            \"average_word_to_guess\": group[f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins\": group.loc[wins, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_lose\": group.loc[losses, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_wins_by_killer_card\": group.loc[wins & killer_word, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_to_guess_when_loses_by_killer_card\": group.loc[losses & killer_word, f'{prefix}avg_words_2guess'].mean(),\n",
        "            \"average_word_guessed\": group[f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins\": group.loc[wins, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_lose\": group.loc[losses, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_wins_by_killer_card\": group.loc[wins & killer_word, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_word_guessed_when_loses_by_killer_card\": group.loc[losses & killer_word, f'{prefix}avg_words_guessed'].mean(),\n",
        "            \"average_turns\": group[f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_wins\": group.loc[wins, f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_lose\": group.loc[losses, f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_wins_by_ending_cards\": group.loc[wins & card_finished, f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_loses_by_ending_cards\": group.loc[losses & card_finished, f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_wins_by_killer_cards\": group.loc[wins & killer_word, f'{prefix}turns'].mean(),\n",
        "            \"average_turns_when_loses_by_killer_cards\": group.loc[losses & killer_word, f'{prefix}turns'].mean(),\n",
        "            \"total_cib\": group[f'{prefix}cib'].sum()\n",
        "        }\n",
        "\n",
        "    # Metrics for agents playing as Red\n",
        "    red_metrics = df.groupby(\"number_red_agents\").apply(lambda g: calculate_metrics(g, \"red\")).apply(pd.Series)\n",
        "    red_metrics['role'] = 'red'\n",
        "\n",
        "    # Metrics for agents playing as Blue\n",
        "    blue_metrics = df.groupby(\"number_blue_agents\").apply(lambda g: calculate_metrics(g, \"blue\")).apply(pd.Series)\n",
        "    blue_metrics['role'] = 'blue'\n",
        "\n",
        "    # Combine overall metrics\n",
        "    overall_metrics = pd.concat([red_metrics, blue_metrics]).reset_index(drop=True)\n",
        "\n",
        "    # Save the results to an Excel file with three sheets\n",
        "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
        "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
        "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
        "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "IsXtYOi2JvZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output file paths\n",
        "input_path = 'path_to_your_input_file.xlsx'  # Replace with your input file path\n",
        "output_path = 'path_to_your_output_file.xlsx'  # Replace with your output file path\n",
        "\n",
        "# Run the process\n",
        "process_agents_data(input_path, output_path)"
      ],
      "metadata": {
        "id": "9Ioe0gMuJ9L1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "codenames_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}