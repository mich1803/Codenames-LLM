{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\OneDrive\\Desktop\\Codenames Progetto PDE\\Codenames-LLM\\codenames_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import codenamesLLM\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 13/23 [00:00<00:00, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing claude-3-5-haiku-latest vs gpt-3.5-turbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [04:17<00:00, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BLUE', 'killer word selected', 5, ['Team RED spymaster said: GAME (3).', 'Team RED said: DICE. The word was RED.', 'Team RED said: ROULETTE. The word was neutral.', 'Team BLUE spymaster said: SILVER (2).', 'Team BLUE said: COPPER. The word was neutral.', 'Team RED spymaster said: AUTHORITY (4).', 'Team RED said: POLICE. The word was neutral.', 'Team BLUE spymaster said: EQUESTRIAN (2).', 'Team BLUE said: HORSESHOE. The word was BLUE.', 'Team BLUE said: HORSE. The word was not in board', 'Team RED spymaster said: DOCUMENT (3).', 'Team RED said: PAPER. The word was RED.', 'Team RED said: ROOT. The word was KILLER.'], 0, 0)\n",
      "Executed claude-3-5-haiku-latest vs gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to your Excel file\n",
    "file_path = \"experiment_data\\model_tournament\\model_tournament_missing.xlsx\" #compy the model_tournament_input to use one new\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Iterate through the rows using titled columns\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Access values using column titles\n",
    "    red_team = row['red_model']  # Replace with the actual column title for the red team\n",
    "    blue_team = row['blue_model']  # Replace with the actual column title for the blue team\n",
    "    playable = True\n",
    "\n",
    "\n",
    "    already_played = pd.notna(row['winner'])\n",
    "    \n",
    "    if ((pd.notna(red_team) and pd.notna(blue_team)) and not(already_played)) and playable:  # Check if both values are not NaN\n",
    "        try:\n",
    "            print(f\"Playing {red_team} vs {blue_team}...\")\n",
    "            # Call your function and get the result\n",
    "            result = codenamesLLM.play_game(red_model = red_team, blue_model = blue_team)\n",
    "            print(result)\n",
    "            red_stats = codenamesLLM.analyze_team_guesses(result[3], \"RED\")\n",
    "            blue_stats = codenamesLLM.analyze_team_guesses(result[3], \"BLUE\")\n",
    "\n",
    "            df.at[index, 'red_model'] = red_team\n",
    "            df.at[index, 'blue_model'] = blue_team\n",
    "            df.at[index, 'winner'] = result[0]  \n",
    "            df.at[index, 'red_avg_words_2guess'] = red_stats['average_expected_guesses']\n",
    "            df.at[index, 'blue_avg_words_2guess'] = blue_stats['average_expected_guesses']\n",
    "            df.at[index, 'red_avg_words_guessed'] = red_stats['average_correct_guesses']\n",
    "            df.at[index, 'blue_avg_words_guessed'] = blue_stats['average_correct_guesses']\n",
    "            df.at[index, 'reason'] = result[1]\n",
    "            df.at[index, 'red_turns'] = red_stats['total_hints']\n",
    "            df.at[index, 'blue_turns'] = blue_stats['total_hints']\n",
    "            df.at[index, 'red_cib'] = result[4]\n",
    "            df.at[index, 'blue_cib'] = result[5]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"skipped game between {red_team} and {blue_team}: {e}\")\n",
    "\n",
    "    # Write the updated DataFrame back to the same Excel file\n",
    "    df.to_excel(file_path, index=False)\n",
    "    if not already_played:\n",
    "        print(f\"Executed {red_team} vs {blue_team}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_tournament_data(input_path, output_path):\n",
    "    # Load the data\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # Function to calculate metrics\n",
    "    def calculate_metrics(group):\n",
    "        wins = group['winner'] == group['role'].str.upper()\n",
    "        losses = ~wins\n",
    "        card_finished = group['reason'] == 'cards finished'\n",
    "        killer_word = group['reason'] == 'killer word selected'\n",
    "\n",
    "        return {\n",
    "            \"model_name\": group[\"model\"].iloc[0],\n",
    "            \"games_played\": len(group),\n",
    "            \"wins\": wins.sum(),\n",
    "            \"win_percentage\": 100 * wins.sum() / len(group),\n",
    "            \"win_by_cards_finished\": (wins & card_finished).sum(),\n",
    "            \"wins_by_killer_words\": (wins & killer_word).sum(),\n",
    "            \"losses_by_card_finished\": (losses & card_finished).sum(),\n",
    "            \"losses_by_killer_words\": (losses & killer_word).sum(),\n",
    "            \"average_word_to_guess\": group['avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins\": group.loc[wins, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_lose\": group.loc[losses, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_to_guess_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_2guess'].mean(),\n",
    "            \"average_word_guessed\": group['avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins\": group.loc[wins, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_lose\": group.loc[losses, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_wins_by_killer_card\": group.loc[wins & killer_word, 'avg_words_guessed'].mean(),\n",
    "            \"average_word_guessed_when_loses_by_killer_card\": group.loc[losses & killer_word, 'avg_words_guessed'].mean(),\n",
    "            \"average_turns\": group['turns'].mean(),\n",
    "            \"average_turns_when_wins\": group.loc[wins, 'turns'].mean(),\n",
    "            \"average_turns_when_lose\": group.loc[losses, 'turns'].mean(),\n",
    "            \"average_turns_when_wins_by_ending_cards\": group.loc[wins & card_finished, 'turns'].mean(),\n",
    "            \"average_turns_when_loses_by_ending_cards\": group.loc[losses & card_finished, 'turns'].mean(),\n",
    "            \"average_turns_when_wins_by_killer_cards\": group.loc[wins & killer_word, 'turns'].mean(),\n",
    "            \"average_turns_when_loses_by_killer_cards\": group.loc[losses & killer_word, 'turns'].mean(),\n",
    "            \"total_cib\": group['cib'].sum()\n",
    "        }\n",
    "\n",
    "    # Reshape the dataset to treat roles equivalently\n",
    "    red_df = df.rename(columns=lambda x: x.replace('red_', '')).assign(role='red', model=df['red_model'])\n",
    "    blue_df = df.rename(columns=lambda x: x.replace('blue_', '')).assign(role='blue', model=df['blue_model'])\n",
    "    combined_df = pd.concat([red_df, blue_df], ignore_index=True)\n",
    "\n",
    "    # Metrics for models as a whole\n",
    "    overall_metrics = combined_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "\n",
    "    # Metrics for models playing as Red\n",
    "    red_metrics = red_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "    red_metrics['role'] = 'red'\n",
    "\n",
    "    # Metrics for models playing as Blue\n",
    "    blue_metrics = blue_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
    "    blue_metrics['role'] = 'blue'\n",
    "\n",
    "    # Save the results to an Excel file with three sheets\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        overall_metrics.to_excel(writer, sheet_name='Overall', index=False)\n",
    "        red_metrics.to_excel(writer, sheet_name='Red', index=False)\n",
    "        blue_metrics.to_excel(writer, sheet_name='Blue', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_16932\\3693970932.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  overall_metrics = combined_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_16932\\3693970932.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  red_metrics = red_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_16932\\3693970932.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  blue_metrics = blue_df.groupby(\"model\").apply(calculate_metrics).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "input_path = 'experiment_data\\model_tournament\\model_tournament.xlsx'  # Replace with your input file path\n",
    "output_path = 'experiment_data\\model_tournament\\model_tournament_stats.xlsx'  # Replace with your output file path\n",
    "\n",
    "# Run the process\n",
    "process_tournament_data(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codenames_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
