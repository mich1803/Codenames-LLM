![Repository banner](media/codenames_banner.jpg)
### Codenames LLM 

This project aims to evaluate the performance of popular Large Language Models (LLMs) through competitive gameplay. The LLMs will be pitted against each other in the board game Codenames, with teams composed entirely of LLMs, entirely of humans, and mixed teams. The goal is to assess the strategic thinking and collaboration capabilities of LLMs in comparison to human players. By analyzing the gameplay, we aim to identify the strengths and weaknesses of different LLMs in terms of language understanding, strategic planning, and teamwork. The findings could help improve the design and training of future LLMs.
